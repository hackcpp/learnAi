{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-deepseek\n",
    "%pip install langchain-ollama\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\",override=True)\n",
    "from os import getenv\n",
    "\n",
    "key = getenv(\"DEEPSEEK_API_KEY\") \n",
    "url = getenv(\"DEEPSEEK_API_BASE\")\n",
    "model = getenv(\"DEEPSEEK_MODEL\")\n",
    "rmodel = getenv(\"DEEPSEEK_RMODEL\")\n",
    "\n",
    "print(key, url, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_base=url,\n",
    "    api_key=key\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"deepseek-r1:latest\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "key = getenv(\"SF_API_KEY\") \n",
    "url = getenv(\"SF_API_BASE\")\n",
    "model = getenv(\"SF_MODEL\")\n",
    "rmodel = getenv(\"SF_RMODEL\")\n",
    "\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = key\n",
    "os.environ[\"DEEPSEEK_API_BASE\"] = url\n",
    "print(key, url, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_base=url,\n",
    "    api_key=key\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to chinese. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_base=url,\n",
    "    api_key=key\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Chinese.\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_base=url,\n",
    "    api_key=key\n",
    ")\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), \n",
    "     (\"user\", human_template)]\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "# print(chain)\n",
    "print(chain.invoke({\"language\": \"Chinese\", \"text\": \"hi!\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_base=url,\n",
    "    api_key=key\n",
    ")\n",
    "\n",
    "system_template = SystemMessagePromptTemplate.from_template( \"Translate the following from English into {language}\")\n",
    "human_template = HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_template, \n",
    "     human_template]\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "# print(chain)\n",
    "print(chain.invoke({\"language\": \"Chinese\", \"text\": \"hi!\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义我们想要接收的数据格式\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class FlowerDescription(BaseModel):\n",
    "    flower_type: str = Field(description=\"鲜花的种类\")\n",
    "    description: str = Field(description=\"鲜花的描述文案\")\n",
    "\n",
    "# 创建输出解析器\n",
    "output_parser = PydanticOutputParser(pydantic_object=FlowerDescription)\n",
    "\n",
    "# 获取输出格式指示\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "# 打印提示\n",
    "# print(\"输出格式：\",format_instructions)\n",
    "\n",
    "# 创建提示模板\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"您是一位专业的鲜花店文案撰写员。\n",
    "对于{flower} ，您能提供一个吸引人的简短中文描述吗？\n",
    "{format_instructions}\"\"\")\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_key=key,\n",
    "    api_base=url,\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | output_parser\n",
    "out = chain.invoke({\"flower\":\"玫瑰\", \"format_instructions\":format_instructions})\n",
    "print(out.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需要的库和模块\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.output_parsers import PydanticOutputParser,OutputFixingParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# 使用Pydantic创建一个数据格式，表示花\n",
    "class Flower(BaseModel):\n",
    "    name: str = Field(description=\"name of a flower\")\n",
    "    colors: List[str] = Field(description=\"the colors of this flower\")\n",
    "# 定义一个用于获取某种花的颜色列表的查询\n",
    "flower_query = \"Generate the charaters for a random flower.\"\n",
    "\n",
    "# 定义一个格式不正确的输出\n",
    "misformatted = \"{'name': '康乃馨', 'colors': ['粉红色','白色','红色','紫色','黄色']}\"\n",
    "\n",
    "# 创建一个用于解析输出的Pydantic解析器，此处希望解析为Flower格式\n",
    "parser = PydanticOutputParser(pydantic_object=Flower)\n",
    "# 使用Pydantic解析器解析不正确的输出\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_key=key,\n",
    "    api_base=url,\n",
    ")\n",
    "# 使用OutputFixingParser创建一个新的解析器，该解析器能够纠正格式不正确的输出\n",
    "fix_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "# 使用新的解析器解析不正确的输出\n",
    "result = fix_parser.parse(misformatted) # 错误被自动修正\n",
    "print(result) # 打印解析后的输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "input_data = \"What is the capital of France?\"\n",
    "summary_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Summarize this: {input}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "sentiment_chain = (\n",
    "    ChatPromptTemplate.from_template(\"What is the sentiment of this: {input}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"summary\": summary_chain,\n",
    "    \"sentiment\": sentiment_chain\n",
    "})\n",
    "parallel_result = parallel_chain.invoke({\"input\": input_data})\n",
    "print(parallel_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_key=key,\n",
    "    api_base=url\n",
    ")\n",
    "\n",
    "# 定义子链\n",
    "tech_prompt = ChatPromptTemplate.from_template(\n",
    "    \"作为科技作者，用专业术语解释：{concept}\"\n",
    ")\n",
    "sports_prompt = ChatPromptTemplate.from_template(\n",
    "    \"作为体育解说员，用生动语言描述：{concept}\"\n",
    ")\n",
    "general_prompt = ChatPromptTemplate.from_template(\n",
    "    \"用通俗语言解释：{concept}\"\n",
    ")\n",
    "\n",
    "tech_chain = tech_prompt | llm | StrOutputParser()\n",
    "sports_chain = sports_prompt | llm | StrOutputParser()\n",
    "general_chain = general_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 构建分支逻辑\n",
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: x[\"topic\"] == \"科技\", tech_chain),\n",
    "    (lambda x: x[\"topic\"] == \"体育\", sports_chain),\n",
    "    general_chain\n",
    ")\n",
    "\n",
    "# 完整执行链\n",
    "# full_chain = RunnableParallel({  # 并行处理输入\n",
    "#     \"concept\": lambda x: x[\"concept\"],\n",
    "#     \"topic\": lambda x: x[\"topic\"]\n",
    "# }) | branch_chain\n",
    "full_chain = branch_chain\n",
    "\n",
    "print(\"***********************\")\n",
    "print(full_chain.invoke({\n",
    "    \"concept\": \"神经网络\", \n",
    "    \"topic\": \"科技\"\n",
    "}))\n",
    "print(\"***********************\")\n",
    "\n",
    "print(full_chain.invoke({\n",
    "    \"concept\": \"越位\", \n",
    "    \"topic\": \"体育\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains  import LLMChain, SequentialChain\n",
    "\n",
    "\n",
    "# 第一个LLMChain：生成鲜花的介绍\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_key=key,\n",
    "    api_base=url,\n",
    ")\n",
    "template = \"\"\"\n",
    "你是一个植物学家。给定花的名称和类型，你需要为这种花写一个200字左右的介绍。\n",
    "花名: {name}\n",
    "颜色: {color}\n",
    "植物学家: 这是关于上述花的介绍:\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "introduction_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    output_key=\"introduction\"\n",
    ")\n",
    "\n",
    "# 第二个LLMChain：根据鲜花的介绍写出鲜花的评论\n",
    "template = \"\"\"\n",
    "你是一位鲜花评论家。给定一种花的介绍，你需要为这种花写一篇200字左右的评论。\n",
    "鲜花介绍:\n",
    "{introduction}\n",
    "花评人对上述花的评论:\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "review_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    output_key=\"review\"\n",
    ")\n",
    "\n",
    "# 第三个LLMChain：根据鲜花的介绍和评论写出一篇自媒体的文案\n",
    "template = \"\"\"\n",
    "你是一家花店的社交媒体经理。给定一种花的介绍和评论，你需要为这种花写一篇社交媒体的帖子，300字左右。\n",
    "鲜花介绍:\n",
    "{introduction}\n",
    "花评人对上述花的评论:\n",
    "{review}\n",
    "社交媒体帖子:\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "social_post_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    output_key=\"social_post_text\"\n",
    ")\n",
    "\n",
    "# 总的链：按顺序运行三个链\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[introduction_chain, review_chain, social_post_chain],\n",
    "    input_variables=[\"name\", \"color\"],\n",
    "    output_variables=[\"introduction\", \"review\", \"social_post_text\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 运行链并打印结果\n",
    "result = overall_chain.invoke({\n",
    "    \"name\": \"玫瑰\",\n",
    "    \"color\": \"黑色\"\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import (\n",
    "    ConversationSummaryBufferMemory,\n",
    "    ConversationBufferMemory\n",
    ")\n",
    "\n",
    "print(key,url)\n",
    "# 初始化大语言模型\n",
    "llm = ChatDeepSeek(\n",
    "    model=model,\n",
    "    api_key=key,\n",
    "    api_base=url,\n",
    ")\n",
    "\n",
    "# 初始化对话链\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "# 第一天的对话\n",
    "# 回合1\n",
    "result = conversation(\"我姐姐明天要过生日，我需要一束生日花束。\")\n",
    "print(result)\n",
    "# 回合2\n",
    "# result = conversation(\"她喜欢粉色玫瑰，颜色是粉色的。\")\n",
    "# print(\"\\n第二次对话后的记忆:\\n\", conversation.memory.buffer)\n",
    "# print(result)\n",
    "\n",
    "# 第二天的对话\n",
    "# 回合3\n",
    "# result = conversation(\"我又来了，还记得我昨天为什么要来买花吗？\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入langchain的实用工具和相关的模块\n",
    "from langchain import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=rmodel,\n",
    "    api_key=key,\n",
    "    api_base=url,\n",
    ")\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///test.db\")\n",
    "\n",
    "# 创建SQL数据库链实例，它允许我们使用LLM来查询SQL数据库\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
    "\n",
    "response = db_chain.run(\"数据库中有几张表\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage,AIMessage\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=rmodel,\n",
    "    api_key=key,\n",
    "    api_base=url,\n",
    ")\n",
    "\n",
    "llm.invoke([\n",
    "    SystemMessage(\"Translate the following from English into Chinese.\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
